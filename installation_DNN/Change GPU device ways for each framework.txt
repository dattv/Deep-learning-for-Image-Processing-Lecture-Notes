


https://github.com/carla-simulator/carla/issues/116


You can easily configure the GPU using these commands for various frameworks:

>>>>>>>>>>Tensorflow<<<<<<<<<

with tf.device('/gpu:1')

>>>>>>>>>>Keras<<<<<<<<<

from keras import backend as K
import tensorflow as tf
with K.tf.device('/gpu:1'):
    config = tf.ConfigProto(intra_op_parallelism_threads=4,\
           inter_op_parallelism_threads=4, allow_soft_placement=True,\
           device_count = {'CPU' : 1, 'GPU' : 1})
    session = tf.Session(config=config)
    K.set_session(session)

>>>>>>>>>>Theano<<<<<<<<<
THEANO_FLAGS='floatX=float32,device=cuda0,gpuarray.preallocate=1' python <yourScript>.py
or even change the Theano rc file ($HOME/.theanorc):

[global]
floatX = float32
device = cuda0

[gpuarray]
preallocate = 1

>>>>>>>>>> Other Methods <<<<<<<<<
The other way is using an environmental variable, only works when used before starting your script:

$ export CUDA_VISIBLE_DEVICES=0

You can even set that environmental variable in your python code before importing framework:

import os
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID" 
os.environ["CUDA_VISIBLE_DEVICES"] = ""







export http_proxy=
export https_proxy=


echo $http_proxy
echo $https_proxy


nvidia-smi -l 1




ERROR:
tensorflow.python.framework.errors_impl.InvalidArgumentError: device CUDA:0 not supported by XLA service
	while setting up XLA_GPU_JIT device number 0


SOLUTION:

import os
os.environ["CUDA_VISIBLE_DEVICES"] = "1"













